{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeWordLengthFn(beam.DoFn):\n",
    "    def process(self, x):\n",
    "        return [len(x)]\n",
    "\n",
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "\n",
    "    lines = p | beam.Create([\n",
    "        'this', 'is', 'a', 'list'\n",
    "    ])\n",
    "\n",
    "    word_lengths = lines | beam.ParDo(ComputeWordLengthFn())\n",
    "\n",
    "    (word_lengths | beam.io.WriteToText('output.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\r\n",
      "2\r\n",
      "1\r\n",
      "4\r\n"
     ]
    }
   ],
   "source": [
    "!cat output.txt-00000-of-00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    lines = p | beam.Create([\n",
    "        'this', 'is', 'a', 'list'\n",
    "    ])\n",
    "\n",
    "    word_lengths = lines | beam.Map(lambda x: '%s,%s'%(x,len(x)))\n",
    "\n",
    "    (word_lengths | beam.io.WriteToText('output-2.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this,4\r\n",
      "is,2\r\n",
      "a,1\r\n",
      "list,4\r\n"
     ]
    }
   ],
   "source": [
    "!cat output-2.txt-00000-of-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    lines = p | beam.io.ReadFromText('group-by-key-input.csv')\n",
    "    \n",
    "    key_values = lines | beam.Map(lambda x: x.split(','))\n",
    "    \n",
    "    group_by = key_values | beam.GroupByKey()\n",
    "    \n",
    "    format_out_lines = group_by | beam.Map(lambda x: '%s,%s'%(x[0], x[1]))\n",
    "    \n",
    "    (format_out_lines | beam.io.WriteToText('output-3.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree,[u'2']\r\n",
      "and,[u'1', u'2', u'6']\r\n",
      "cat,[u'1', u'5', u'9']\r\n",
      "jump,[u'3']\r\n",
      "dog,[u'5', u'2']\r\n"
     ]
    }
   ],
   "source": [
    "!cat output-3.txt-00000-of-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoGroupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    emails_list = [\n",
    "        ('amy', 'amy@example.com'),\n",
    "        ('carl', 'carl@example.com'),\n",
    "        ('julia', 'julia@example.com'),\n",
    "        ('carl', 'carl@email.com'),\n",
    "    ]\n",
    "    phones_list = [\n",
    "        ('amy', '111-222-3333'),\n",
    "        ('james', '222-333-4444'),\n",
    "        ('amy', '333-444-5555'),\n",
    "        ('carl', '444-555-6666'),\n",
    "    ]\n",
    "\n",
    "    emails = p | 'CreateEmails' >> beam.Create(emails_list)\n",
    "    phones = p | 'CreatePhones' >> beam.Create(phones_list)\n",
    "\n",
    "    results = ({'emails': emails, 'phones': phones}\n",
    "           | beam.CoGroupByKey())\n",
    "\n",
    "    def join_info(name_info):\n",
    "      (name, info) = name_info\n",
    "      return '%s; %s; %s' %\\\n",
    "          (name, sorted(info['emails']), sorted(info['phones']))\n",
    "\n",
    "    contact_lines = results | beam.Map(join_info)\n",
    "    \n",
    "    (contact_lines | beam.io.WriteToText('output-4.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amy; ['amy@example.com']; ['111-222-3333', '333-444-5555']\r\n",
      "james; []; ['222-333-4444']\r\n",
      "julia; ['julia@example.com']; []\r\n",
      "carl; ['carl@email.com', 'carl@example.com']; ['444-555-6666']\r\n"
     ]
    }
   ],
   "source": [
    "!cat output-4.txt-00000-of-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine\n",
    "\n",
    "For combining values accross a `PCollection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    pc = p | beam.Create([1, 10, 100, 1000])\n",
    "\n",
    "    def bounded_sum(values, bound=500):\n",
    "        return min(sum(values), bound)\n",
    "\n",
    "    # if operations are the same, they need a unique label per the Pipeline\n",
    "    small_sum = pc | \"SmallSum\" >> beam.CombineGlobally(bounded_sum)\n",
    "    large_sum = pc | \"LargeSum\" >> beam.CombineGlobally(bounded_sum, bound=5000)\n",
    "    \n",
    "    (small_sum | \"WriteSmallSum\" >> beam.io.WriteToText('output-5.txt'))\n",
    "\n",
    "    # NOTE: writing to the same file twice overwrites the value\n",
    "    #(large_sum | \"WriteLargeSum\" >> beam.io.WriteToText('output-5.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\r\n"
     ]
    }
   ],
   "source": [
    "!cat output-5.txt-00000-of-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombineFn\n",
    "\n",
    "For more sophisticated combining, i.e.\n",
    "\n",
    "> must perform additional pre- or post-processing, might change the output type, or takes the key into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageFn(beam.CombineFn):\n",
    "    def create_accumulator(self):\n",
    "        return (0.0, 0)\n",
    "\n",
    "    def add_input(self, sum_count, input):\n",
    "        (sum, count) = sum_count\n",
    "        return sum + input, count + 1\n",
    "\n",
    "    def merge_accumulators(self, accumulators):\n",
    "        sums, counts = zip(*accumulators)\n",
    "        return sum(sums), sum(counts)\n",
    "\n",
    "    def extract_output(self, sum_count):\n",
    "        (sum, count) = sum_count\n",
    "        return sum / count if count else float('NaN')\n",
    "\n",
    "    \n",
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    pc = p | beam.Create([1, 2, 3, 20])\n",
    "    \n",
    "    average = pc | beam.CombineGlobally(AverageFn())\n",
    "    \n",
    "    (average | beam.io.WriteToText('output-6.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5\r\n"
     ]
    }
   ],
   "source": [
    "!cat output-6.txt-00000-of-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombinePerKey\n",
    "\n",
    "Combine values per Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_key_and_int(x):\n",
    "    k, v = x.split(',')\n",
    "    return k, int(v)\n",
    "\n",
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    lines = p | beam.io.ReadFromText('group-by-key-input.csv')\n",
    "    \n",
    "    key_values = lines | beam.Map(split_key_and_int)\n",
    "    \n",
    "    average_per_key = (\n",
    "        key_values | beam.CombinePerKey(beam.combiners.MeanCombineFn()))\n",
    "\n",
    "    (average_per_key | beam.io.WriteToText('output-7.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'tree', 2.0)\r\n",
      "(u'and', 3.0)\r\n",
      "(u'cat', 5.0)\r\n",
      "(u'jump', 3.0)\r\n",
      "(u'dog', 3.5)\r\n"
     ]
    }
   ],
   "source": [
    "!cat output-7.txt-00000-of-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten\n",
    "\n",
    "Use to combine 2 or more `PCollection`'s (must have the same data type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    work_emails_list = [\n",
    "        ('amy', 'amy@work.com'),\n",
    "        ('carl', 'carl@work.com')\n",
    "    ]\n",
    "    personal_emails_list = [\n",
    "        ('jay', 'julia@personal.com'),\n",
    "        ('steve', 'carl@personal.com'),\n",
    "    ]\n",
    "\n",
    "    work_emails = p | 'CreateWorkEmails' >> beam.Create(work_emails_list)\n",
    "    personal_emails = p | 'CreatePersonalEmails' >> beam.Create(personal_emails_list)\n",
    "\n",
    "    merged = (work_emails_list, personal_emails_list) | beam.Flatten()\n",
    "    \n",
    "    (merged | beam.io.WriteToText('output-8.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('amy', 'amy@work.com')\r\n",
      "('carl', 'carl@work.com')\r\n",
      "('jay', 'julia@personal.com')\r\n",
      "('steve', 'carl@personal.com')\r\n"
     ]
    }
   ],
   "source": [
    "!cat output-8.txt-00000-of-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition\n",
    "\n",
    "To separate a `PCollection` into 2 or more `PCollection`'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    emails_list = [\n",
    "        ('amy', 'amy@work.com'),\n",
    "        ('carl', 'carl@work.com'),\n",
    "        ('jay', 'julia@personal.com'),\n",
    "        ('steve', 'carl@personal.com'),\n",
    "    ]\n",
    "\n",
    "    emails = p | 'CreateEmails' >> beam.Create(emails_list)\n",
    "    \n",
    "    def partition_fn(value, num_partitions):\n",
    "        name, email = value\n",
    "        if email.endswith('work.com'):\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "    email_partition = emails | beam.Partition(partition_fn, 2)\n",
    "\n",
    "    (email_partition[0] | \"WritePartition0\" >> beam.io.WriteToText('output-9-partition-0.txt'))\n",
    "    (email_partition[1] | \"WritePartition1\" >> beam.io.WriteToText('output-9-partition-1.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('amy', 'amy@work.com')\r\n",
      "('carl', 'carl@work.com')\r\n"
     ]
    }
   ],
   "source": [
    "!cat output-9-partition-0.txt-00000-of-00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('jay', 'julia@personal.com')\r\n",
      "('steve', 'carl@personal.com')\r\n"
     ]
    }
   ],
   "source": [
    "!cat output-9-partition-1.txt-00000-of-00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
