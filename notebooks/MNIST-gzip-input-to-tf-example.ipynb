{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aaron/Documents/github/tensorflow/tensorflow/examples/how_tos/reading_data\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf8' codec can't decode byte 0xea in position 6: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5ac53206c573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     lines = p | beam.io.ReadFromText(\n\u001b[1;32m      5\u001b[0m         \u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         compression_type=beam.io.filesystem.CompressionTypes.GZIP)\n\u001b[0m",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/pipeline.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    424\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/pipeline.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, test_runner_api)\u001b[0m\n\u001b[1;32m    404\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_runner_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_fake_coders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m           self._options).run(False)\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTypeOptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruntime_type_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/pipeline.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, test_runner_api)\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/direct/direct_runner.pyc\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    130\u001b[0m       \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBundleBasedDirectRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/portability/fn_api_runner.pyc\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    273\u001b[0m         options.view_as(pipeline_options.ProfilingOptions))\n\u001b[1;32m    274\u001b[0m     return self.run_via_runner_api(pipeline.to_runner_api(\n\u001b[0;32m--> 275\u001b[0;31m         default_environment=self._default_environment))\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_via_runner_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/portability/fn_api_runner.pyc\u001b[0m in \u001b[0;36mrun_via_runner_api\u001b[0;34m(self, pipeline_proto)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_via_runner_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/portability/fn_api_runner.pyc\u001b[0m in \u001b[0;36mrun_stages\u001b[0;34m(self, stage_context, stages)\u001b[0m\n\u001b[1;32m    352\u001b[0m               \u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m               \u001b[0mpcoll_buffers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m               stage_context.safe_coders)\n\u001b[0m\u001b[1;32m    355\u001b[0m           \u001b[0mmetrics_by_stage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_bundle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m           monitoring_infos_by_stage[stage.name] = (\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/portability/fn_api_runner.pyc\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self, worker_handler_factory, pipeline_components, stage, pcoll_buffers, safe_coders)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mcontroller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_input_coder_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_bundle_descriptor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_bundle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m             data_input, data_output)\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minput_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptransform_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/portability/fn_api_runner.pyc\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, inputs, expected_outputs)\u001b[0m\n\u001b[1;32m   1204\u001b[0m         process_bundle=beam_fn_api_pb2.ProcessBundleRequest(\n\u001b[1;32m   1205\u001b[0m             process_bundle_descriptor_reference=self._bundle_descriptor.id))\n\u001b[0;32m-> 1206\u001b[0;31m     \u001b[0mresult_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_controller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     with ProgressRequester(\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/portability/fn_api_runner.pyc\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    819\u001b[0m       \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstruction_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'control_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uid_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CONTROL REQUEST %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CONTROL RESPONSE %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mControlFuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/worker/sdk_worker.pyc\u001b[0m in \u001b[0;36mdo_instruction\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;31m# E.g. if register is set, this will call self.register(request.register))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       return getattr(self, request_type)(getattr(request, request_type),\n\u001b[0;32m--> 265\u001b[0;31m                                          request.instruction_id)\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/worker/sdk_worker.pyc\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, request, instruction_id)\u001b[0m\n\u001b[1;32m    279\u001b[0m         request.process_bundle_descriptor_reference) as bundle_processor:\n\u001b[1;32m    280\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mdelayed_applications\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbundle_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_bundle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m       return beam_fn_api_pb2.InstructionResponse(\n\u001b[1;32m    283\u001b[0m           \u001b[0minstruction_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstruction_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/worker/bundle_processor.pyc\u001b[0m in \u001b[0;36mprocess_bundle\u001b[0;34m(self, instruction_id)\u001b[0m\n\u001b[1;32m    545\u001b[0m           input_op_by_target[\n\u001b[1;32m    546\u001b[0m               \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimitive_transform_reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m           ].process_encoded(data.data)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m       \u001b[0;31m# Finish all operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/worker/bundle_processor.pyc\u001b[0m in \u001b[0;36mprocess_encoded\u001b[0;34m(self, encoded_windowed_values)\u001b[0m\n\u001b[1;32m    137\u001b[0m       decoded_value = self.windowed_coder_impl.decode_from_stream(\n\u001b[1;32m    138\u001b[0m           input_stream, True)\n\u001b[0;32m--> 139\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtry_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction_of_remainder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_buffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/worker/operations.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/worker/operations.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/worker/operations.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.SingletonConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/worker/operations.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.ImpulseReadOperation.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/runners/worker/operations.so\u001b[0m in \u001b[0;36mapache_beam.runners.worker.operations.ImpulseReadOperation.process\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/io/concat_source.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, range_tracker)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       for record in self._source_bundles[source_ix].source.read(\n\u001b[0;32m---> 86\u001b[0;31m           range_tracker.sub_range_tracker(source_ix)):\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/io/textio.pyc\u001b[0m in \u001b[0;36mread_records\u001b[0;34m(self, file_name, range_tracker)\u001b[0m\n\u001b[1;32m    200\u001b[0m           \u001b[0mnext_record_start_position\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnum_bytes_to_next_record\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_bytes_to_next_record\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/apache_beam/coders/coders.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mis_deterministic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aaron/Documents/github/tfx/venv/lib/python2.7/encodings/utf_8.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf8' codec can't decode byte 0xea in position 6: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "infile = '/tmp/data/mnist/train/images.gz'\n",
    "\n",
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    lines = p | beam.io.Read(\n",
    "        infile, \n",
    "        compression_type=beam.io.filesystem.CompressionTypes.GZIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "with gfile.Open(infile, 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "        data = bytestream.read(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.uint32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = numpy.dtype(numpy.uint32).newbyteorder('>')\n",
    "images = numpy.frombuffer(data, dtype=dt)[0]\n",
    "type(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2051"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in-memory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module should implement `base_example_gen_executor.BaseExampleGenExecutor`\n",
    "\n",
    "It will take MNIST data from a given directory and convert it to tf.Example\n",
    "records using Apache Beam for use by its parent's class\n",
    "\n",
    "Helper functions code borrowed from and adapted from here in order to read Gzip MNIST files\n",
    "from an arbitrary location and return them as numpy.ndarray\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/mnist.py\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gzip\n",
    "\n",
    "import numpy\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import random_seed\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util.deprecation import deprecated\n",
    "\n",
    "def _read32(bytestream):\n",
    "  dt = numpy.dtype(numpy.uint32).newbyteorder('>')\n",
    "  return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]\n",
    "\n",
    "def extract_images(f):\n",
    "  \"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\n",
    "\n",
    "  Args:\n",
    "    f: A file object that can be passed into a gzip reader.\n",
    "\n",
    "  Returns:\n",
    "    data: A 4D uint8 numpy array [index, y, x, depth].\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If the bytestream does not start with 2051.\n",
    "\n",
    "  \"\"\"\n",
    "  print('Extracting', f.name)\n",
    "  with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "    magic = _read32(bytestream)\n",
    "    if magic != 2051:\n",
    "      raise ValueError('Invalid magic number %d in MNIST image file: %s' %\n",
    "                       (magic, f.name))\n",
    "    num_images = _read32(bytestream)\n",
    "    rows = _read32(bytestream)\n",
    "    cols = _read32(bytestream)\n",
    "    buf = bytestream.read(rows * cols * num_images)\n",
    "    data = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "    data = data.reshape(num_images, rows, cols, 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(f, one_hot=False, num_classes=10):\n",
    "  \"\"\"Extract the labels into a 1D uint8 numpy array [index].\n",
    "\n",
    "  Args:\n",
    "    f: A file object that can be passed into a gzip reader.\n",
    "    one_hot: Does one hot encoding for the result.\n",
    "    num_classes: Number of classes for the one hot encoding.\n",
    "\n",
    "  Returns:\n",
    "    labels: a 1D uint8 numpy array.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If the bystream doesn't start with 2049.\n",
    "  \"\"\"\n",
    "  print('Extracting', f.name)\n",
    "  with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "    magic = _read32(bytestream)\n",
    "    if magic != 2049:\n",
    "      raise ValueError('Invalid magic number %d in MNIST label file: %s' %\n",
    "                       (magic, f.name))\n",
    "    num_items = _read32(bytestream)\n",
    "    buf = bytestream.read(num_items)\n",
    "    labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "    if one_hot:\n",
    "      return tf.one_hot(labels, num_classes)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_images_and_labels(images_path, labels_path):\n",
    "  \"\"\"\n",
    "  Extract gzip images/labels from path\n",
    "  \"\"\"\n",
    "  with gfile.Open(images_path, 'rb') as f:\n",
    "    images = extract_images(f)\n",
    "\n",
    "  with gfile.Open(labels_path, 'rb') as f:\n",
    "    labels = extract_labels(f)\n",
    "\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/mnist/train/images.gz\n",
      "Extracting /tmp/data/mnist/train/labels.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path = '/tmp/data/mnist/train/images.gz'\n",
    "labels_path = '/tmp/data/mnist/train/labels.gz'\n",
    "    \n",
    "train_images, train_labels = get_images_and_labels(images_path, labels_path)\n",
    "\n",
    "train_images.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/mnist/val/images.gz\n",
      "Extracting /tmp/data/mnist/val/labels.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28, 1), (10000,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path = '/tmp/data/mnist/val/images.gz'\n",
    "labels_path = '/tmp/data/mnist/val/labels.gz'\n",
    "    \n",
    "val_images, val_labels = get_images_and_labels(images_path, labels_path)\n",
    "\n",
    "val_images.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 7), (1, 2), (2, 1), (3, 0), (4, 4)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_w_index = [(i,x) for i,x in enumerate(val_labels)]\n",
    "\n",
    "labels_w_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, (28, 28, 1))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_w_index = [(i,x) for i,x in enumerate(val_images)]\n",
    "\n",
    "images_w_index[0][0], images_w_index[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = val_images\n",
    "N = images.shape[0]\n",
    "rows = images.shape[1]\n",
    "cols = images.shape[2]\n",
    "depth = images.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, rows, cols, depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    }
   ],
   "source": [
    "def group_by_tf_example(key_value):\n",
    "    _, value = key_value\n",
    "    image = value['image'][0]\n",
    "    label = value['label'][0]\n",
    "    example = tf.train.Example(\n",
    "          features=tf.train.Features(\n",
    "              feature={\n",
    "                  'height': _int64_feature(rows),\n",
    "                  'width': _int64_feature(cols),\n",
    "                  'depth': _int64_feature(depth),\n",
    "                  'label': _int64_feature(int(label)),\n",
    "                  'image_raw': _bytes_feature(image.tostring())\n",
    "              })\n",
    "        )\n",
    "    return example\n",
    "\n",
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "    label_line = p | \"CreateLabel\" >> beam.Create(labels_w_index[:1])\n",
    "    image_line = p | \"CreateImage\" >> beam.Create(images_w_index[:1])\n",
    "    \n",
    "    group_by = ({'label': label_line, 'image': image_line}) | beam.CoGroupByKey()\n",
    "    \n",
    "    tf_example = group_by | \"GroupByToTfExample\" >> beam.Map(group_by_tf_example)\n",
    "    \n",
    "    serialize = (tf_example | 'SerializeDeterministically' >>\n",
    "          beam.Map(lambda x: x.SerializeToString(deterministic=True)))\n",
    "        \n",
    "    output = serialize | beam.io.WriteToTFRecord('mnist-out-4', file_name_suffix='.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001f�\b\u0000\u0000\u0000\u0000\u0000\u0000\u0013�ff\u0000��x�\r\n",
      "�\u0017l\\|\\�)�\u0005%\u0019B�R�\\��\\�\\l\u0019���\u0019%\u0010\u0001\u0019�%l\\������E��B�ظ&�qM`c\u00186 d���6*����\u0003��Ǡ`�\t��s�G����\u001e",
      "\u0002U�z��_\u000f�fA'>gggk�7��p�\u001d",
      "���\u0010\u000e)����qik��N\u0007����v�����͊C���\u000f+\\���m�%����%\u000e)����b>��2\u000e9��|qH�?�ẄC���?\u0013\u001c",
      "R��p�U��w[\u0003��y\\q�\u0005��QNbRj\u000e$۰���)�|%s%7f.\u0000�J\u0007�{\u0003\u0000\u0000"
     ]
    }
   ],
   "source": [
    "!cat mnist-out-4-00000-of-00001.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn.python import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-2824f5e8b785>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "WARNING:tensorflow:From /Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aaron/Documents/github/tfx/venv/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x118d0b890>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x118d0b4d0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x118d0b250>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.mnist.read_data_sets('/tmp/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
